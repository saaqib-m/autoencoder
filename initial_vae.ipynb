{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D, Input, Reshape, UpSampling2D, InputLayer, Lambda, ZeroPadding2D, Cropping2D, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, UpSampling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "# from keras import backend as objectives\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "import skimage as sk\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2 as cv2\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# from PIL import ImageFile\n",
    "# ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator\n",
    "# source from https://medium.com/@ensembledme/writing-custom-keras-generators-fe815d992c5a\n",
    "\n",
    "def get_input(path):\n",
    "    \"\"\"get specific image from path\"\"\"\n",
    "    img = imread(path)\n",
    "    return img\n",
    "\n",
    "def preprocess_input(img):\n",
    "    # convert between 0 and 1\n",
    "    return img.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\Saaqib\\Documents\\Imperial\\Research Project\\SWET_data\"\n",
    "img_path = []\n",
    "files = os.listdir(file_path)\n",
    "for root, directories, files in os.walk(file_path, topdown=False):\n",
    "\tfor name in files:\n",
    "\t\timg_path.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for file_path in img_path:\n",
    "    input = get_input(file_path)\n",
    "    input = cv2.resize(input, (256,256))\n",
    "    input = sk.color.rgb2gray(input)\n",
    "    input = preprocess_input(input)\n",
    "    x.append(input)\n",
    "    y.append(input)\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "x_train = x_train.reshape(-1,256,256,1)\n",
    "x_test = x_test.reshape(-1,256,256,1)\n",
    "y_train = x_train.reshape(-1,256,256,1)\n",
    "y_test = x_test.reshape(-1,256,256,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,5)\n",
    "f.set_size_inches(80, 40)\n",
    "for i in range(5,10):\n",
    "    ax[i-5].imshow(x_train[i, :, :, 0].reshape(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 128\n",
    "n_size = 512\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape = (n_size,) , mean = 0, stddev = 1)\n",
    "    return z_mean + K.exp(z_log_sigma/2) * epsilon\n",
    "  \n",
    "def build_conv_vae(input_shape, bottleneck_size, sampling, batch_size = 32):\n",
    "    \n",
    "    # ENCODER\n",
    "    input = Input(shape=(input_shape[0],input_shape[1],input_shape[2]))\n",
    "    x = Conv2D(32,(3,3),activation = 'relu', padding = 'same')(input)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2), padding ='same')(x)\n",
    "    x = Conv2D(64,(3,3),activation = 'relu', padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2), padding ='same')(x)\n",
    "    x = Conv2D(128,(3,3), activation = 'relu', padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2), padding ='same')(x)\n",
    "    x = Conv2D(256,(3,3), activation = 'relu', padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2), padding ='same')(x)\n",
    "    \n",
    "    # Latent Variable Calculation\n",
    "    shape = K.int_shape(x)\n",
    "    \n",
    "    flatten_1 = Flatten()(x)\n",
    "    dense_1 = Dense(bottleneck_size, name='z_mean')(flatten_1)\n",
    "    z_mean = BatchNormalization()(dense_1)\n",
    "\n",
    "    flatten_2 = Flatten()(x)\n",
    "    dense_2 = Dense(bottleneck_size, name ='z_log_sigma')(flatten_2)\n",
    "    z_log_sigma = BatchNormalization()(dense_2)\n",
    "\n",
    "    z = Lambda(sampling)([z_mean, z_log_sigma])\n",
    "    encoder = Model(input, [z_mean, z_log_sigma, z], name = 'encoder')\n",
    "    \n",
    "    # DECODER\n",
    "    latent_input = Input(shape=(bottleneck_size,), name = 'decoder_input')\n",
    "    x = Dense(shape[1]*shape[2]*shape[3])(latent_input)\n",
    "    x = Reshape((shape[1],shape[2],shape[3]))(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    # x = Cropping2D([[0,0],[0,1]])(x)\n",
    "    x = Conv2DTranspose(256,(3,3), activation = 'relu', padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    # x = Cropping2D([[0,1],[0,1]])(x)\n",
    "    x = Conv2DTranspose(128,(3,3), activation = 'relu', padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    # x = Cropping2D([[0,1],[0,1]])(x)\n",
    "    x = Conv2DTranspose(64,(3,3), activation = 'relu', padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    x = Conv2DTranspose(32,(3,3), activation = 'relu', padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    output = Conv2DTranspose(1,(3,3), activation = 'tanh', padding ='same')(x)\n",
    "    decoder = Model(latent_input, output, name = 'decoder')\n",
    "\n",
    "    output_2 = decoder(encoder(input)[2])\n",
    "    vae = Model(input, output_2, name ='vae')\n",
    "    return vae, encoder, decoder, z_mean, z_log_sigma, input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae_2, encoder, decoder, z_mean, z_log_sigma = build_conv_vae((218,178,3), n_size, sampling, batch_size = b_size)\n",
    "vae_2, encoder, decoder, z_mean, z_log_sigma, input_layer = build_conv_vae((256,256,1), n_size, sampling, batch_size = b_size)\n",
    "\n",
    "print(\"encoder summary:\")\n",
    "encoder.summary()\n",
    "print(\"decoder summary:\")\n",
    "decoder.summary()\n",
    "print(\"vae summary:\")\n",
    "vae_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(input_img, output):\n",
    "    # Compute error in reconstruction\n",
    "    reconstruction_loss = mse(K.flatten(input_img) , K.flatten(output))\n",
    "    \n",
    "    # Compute the KL Divergence regularization term\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis = -1)\n",
    "    \n",
    "    # Return the average loss over all images in batch\n",
    "    total_loss = (reconstruction_loss + 0.0001 * kl_loss)    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "vae_2.compile(optimizer='rmsprop', loss= vae_loss,options = run_opts)\n",
    "encoder.compile(optimizer = 'rmsprop', loss = vae_loss)\n",
    "decoder.compile(optimizer = 'rmsprop', loss = vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae_2.fit(x_train, y_train,\n",
    "#                 epochs=50,\n",
    "#                 validation_data=(x_test, y_test))\n",
    "history = vae_2.fit(x_train, y_train, \n",
    "          steps_per_epoch = 400, \n",
    "          validation_data = (x_test, y_test),\n",
    "          epochs=7, \n",
    "          validation_steps= 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_latent = Model(input_layer, encoder)\n",
    "model_latent.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.randint(0,len(y_test))\n",
    "\n",
    "preds = model_latent.predict(y_test[n:n+4])\n",
    "\n",
    "f, ax = plt.subplots(2,2)\n",
    "ax = ax.ravel()\n",
    "for j in range(4):\n",
    "    for i,a in enumerate(range(n,n+3)):\n",
    "        ax[j].imshow(preds[i, :, :, j])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = vae_2.predict(x_test)\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(256,256))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, 5, i + 1 + 5)\n",
    "    plt.imshow(pred[i].reshape(256,256))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test = []\n",
    "# inpp = []\n",
    "# for i in range(len(img_path)):\n",
    "#     inp = get_input(img_path[i])\n",
    "#     inp = preprocess_input(inp)\n",
    "#     inp = cv2.resize(inp, (178,218))\n",
    "#     inpp.append(inp)\n",
    "#     # plt.imshow(inp)\n",
    "# for i in range(len(inpp)):\n",
    "#     x_test.append(inpp[random.randint(0,46)])\n",
    "# x_test = np.array(x_test)\n",
    "# figure_Decoded = vae_2.predict(x_test.astype('float32')/127.5 -1, batch_size = b_size)\n",
    "# figure_original = x_test[0]\n",
    "# figure_decoded = (figure_Decoded[0]+1)/2\n",
    "# for i in range(4):\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(2,4,1+i*2)\n",
    "#     plt.imshow(x_test[i])\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(2,4,2 + i*2)\n",
    "#     plt.imshow((figure_Decoded[i]+1)/2)\n",
    "#     plt.axis('off')\n",
    "# plt.show()  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e16dddf07b681241daaa47640c1db83e99c181a0b2fe1df995963d091a6441eb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
